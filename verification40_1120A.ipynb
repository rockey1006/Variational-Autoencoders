{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "verification40_1120A.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQyvwgi8pmzYXhKN/sM3Af",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockey1006/Variational-Autoencoders/blob/master/verification40_1120A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBiyk65bfgF3"
      },
      "source": [
        "!pip install deepface\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ6Azs8YfojR"
      },
      "source": [
        "from deepface import DeepFace\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iea8DoTWfpyS",
        "outputId": "f109c696-58e7-4515-811c-1c79ca1e6504"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIBKSzZmfwAL"
      },
      "source": [
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/facenet_weights.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in different directory\n",
        "   zipObj.extractall('/root/.deepface/weights/')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZjH63cBgEb5"
      },
      "source": [
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/MyDrive/000031.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in different directory\n",
        "   zipObj.extractall('000031/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a0GzTNarKtc"
      },
      "source": [
        "import imageio\n",
        "import imageio.core.util\n",
        "def silence_imageio_warning(*args, **kwargs):\n",
        "    pass\n",
        "imageio.core.util._precision_warn = silence_imageio_warning\n",
        "import warnings\n",
        "\n",
        "def fxn():\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    fxn()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rvW8x-Oxi5n6",
        "outputId": "0b6d4cbf-c766-40cb-e8e9-82fc8688a85e"
      },
      "source": [
        "import os \n",
        "\n",
        "g = os.walk(r\"/content/000031_new/\")  \n",
        "srcPath='/content/verified_000031/'\n",
        "\n",
        "for path,dir_list,file_list in g:  \n",
        "    for file_name in file_list:  \n",
        "      try:\n",
        "          result  = DeepFace.verify(\"/content/000031_new/000031.png\", os.path.join(path, file_name),model_name=\"Facenet\",distance_metric='euclidean_l2')\n",
        "      except:\n",
        "        continue\n",
        "      result  = DeepFace.verify(\"/content/000031_new/000031.png\", os.path.join(path, file_name),model_name=\"Facenet\",distance_metric='euclidean_l2')\n",
        "       \n",
        "      print(\"euclidean_l2 distance: \",result[\"distance\"])\n",
        "      print(os.path.join(path, file_name))\n",
        "  \n",
        "      if result[\"distance\"]<1.1:\n",
        "        path = os.path.join(srcPath+'/'+file_name)\n",
        "        with open(path, 'rb') as rstream:\n",
        "          container = rstream.read()\n",
        "          with open(path, 'wb') as wstream:\n",
        "            wstream.write(container)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3670052\n",
            "/content/000031_new/a.pngb'No_Beard'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2537636\n",
            "/content/000031_new/a.pngb'Narrow_Eyes'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3221225\n",
            "/content/000031_new/a.pngb'Pale_Skin'.png7.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4240679\n",
            "/content/000031_new/a.pngb'Brown_Hair'.png8.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4384762\n",
            "/content/000031_new/a.pngb'Heavy_Makeup'.png9.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2521697\n",
            "/content/000031_new/a.pngb'Gray_Hair'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4042655\n",
            "/content/000031_new/a.pngb'Wearing_Earrings'.png6.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4003541\n",
            "/content/000031_new/a.pngb'Arched_Eyebrows'.png7.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4272106\n",
            "/content/000031_new/a.pngb'Big_Lips'.png9.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.38076\n",
            "/content/000031_new/a.pngb'Arched_Eyebrows'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Blurry'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3505783\n",
            "/content/000031_new/a.pngb'Bushy_Eyebrows'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.244419\n",
            "/content/000031_new/a.pngb'Mustache'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3729848\n",
            "/content/000031_new/a.pngb'Black_Hair'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.326647\n",
            "/content/000031_new/a.pngb'Wearing_Necklace'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3287888\n",
            "/content/000031_new/a.pngb'Wearing_Earrings'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3839936\n",
            "/content/000031_new/a.pngb'Oval_Face'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.389877\n",
            "/content/000031_new/a.pngb'Brown_Hair'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.350466\n",
            "/content/000031_new/a.pngb'Straight_Hair'.png9.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2526447\n",
            "/content/000031_new/a.pngb'Gray_Hair'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Black_Hair'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Big_Lips'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4365963\n",
            "/content/000031_new/a.pngb'Attractive'.png6.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Wearing_Necklace'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3818657\n",
            "/content/000031_new/a.pngb'Blond_Hair'.png8.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2893759\n",
            "/content/000031_new/a.pngb'Oval_Face'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3803133\n",
            "/content/000031_new/a.pngb'Wavy_Hair'.png8.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2823228\n",
            "/content/000031_new/a.pngb'Sideburns'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.431649\n",
            "/content/000031_new/a.pngb'Bangs'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.1858964\n",
            "/content/000031_new/a.pngb'Receding_Hairline'.png6.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Bald'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3852012\n",
            "/content/000031_new/a.pngb'Oval_Face'.png9.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3308188\n",
            "/content/000031_new/a.pngb'Black_Hair'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4004244\n",
            "/content/000031_new/a.pngb'Brown_Hair'.png5.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Attractive'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3527826\n",
            "/content/000031_new/a.pngb'Young'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2781126\n",
            "/content/000031_new/a.pngb'Smiling'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3924967\n",
            "/content/000031_new/a.pngb'Wavy_Hair'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.39649\n",
            "/content/000031_new/a.pngb'No_Beard'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3717818\n",
            "/content/000031_new/a.pngb'Wearing_Earrings'.png8.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3624561\n",
            "/content/000031_new/a.pngb'Brown_Hair'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3889263\n",
            "/content/000031_new/a.pngb'Wearing_Necklace'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Wavy_Hair'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4458967\n",
            "/content/000031_new/a.pngb'No_Beard'.png9.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3376635\n",
            "/content/000031_new/a.pngb'Rosy_Cheeks'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2800082\n",
            "/content/000031_new/a.pngb'Blurry'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Narrow_Eyes'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3988078\n",
            "/content/000031_new/a.pngb'Wearing_Lipstick'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3533318\n",
            "/content/000031_new/a.pngb'Wearing_Lipstick'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3466854\n",
            "/content/000031_new/a.pngb'Black_Hair'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3538276\n",
            "/content/000031_new/a.pngb'Rosy_Cheeks'.png4.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.4227648\n",
            "/content/000031_new/a.pngb'Wearing_Necklace'.png8.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3174134\n",
            "/content/000031_new/a.pngb'Big_Lips'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3507082\n",
            "/content/000031_new/a.pngb'High_Cheekbones'.png3.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'Smiling'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.3722061\n",
            "/content/000031_new/a.pngb'No_Beard'.png2.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "euclidean_l2 distance:  1.2884995\n",
            "/content/000031_new/a.pngb'No_Beard'.png1.png\n",
            "Using Facenet model backend euclidean_l2 distance.\n",
            "Using Facenet model backend euclidean_l2 distance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1e99dabe2c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mresult\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/000031_new/000031.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Facenet\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistance_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean_l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"euclidean_l2 distance: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepface/DeepFace.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(img1_path, img2_path, model_name, distance_metric, model, enforce_detection, detector_backend)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Facenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using Facenet model backend\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"distance.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DeepFace'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepface/basemodels/Facenet.py\u001b[0m in \u001b[0;36mloadModel\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/uc?id=1971Xk5RwedbudGgTIrGAL4F7Aifu7id1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionResNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;31m#-----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepface/basemodels/Facenet.py\u001b[0m in \u001b[0;36mInceptionResNetV2\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mbranches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbranch_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mmixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Block8_2_Concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1792\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Block8_2_Conv2d_1x1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2598\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1516\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1649\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1651\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1653\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mvia\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVarianceScaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1042\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     return op(\n\u001b[0;32m-> 1044\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,1,384,1792] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKTQSDl53CIw"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "fileName = os.listdir('/content/000031/000031')\n",
        "width = 160\n",
        "height = 160\n",
        "\n",
        "for img in fileName:\n",
        "  pic = Image.open('/content/000031/000031/'+img)\n",
        "  newpic = pic.resize((width,height),Image.ANTIALIAS)\n",
        "  print(newpic)\n",
        "  newpic.save('/content/000031_new/'+img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}