{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_0ne.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxvI9r3vzS/x/uFAxA6SMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockey1006/Variational-Autoencoders/blob/master/random_0ne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq0uYBZTlH4n",
        "outputId": "75ae05f1-82d9-4302-bbfb-d14463510166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71u5CMo1labj"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/LFW1026.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in different directory\n",
        "   zipObj.extractall('LFW')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFILG2N7l_Tw"
      },
      "source": [
        "import os,sys\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        " \n",
        "\n",
        "def random_copyfile(srcPath,dstPath):\n",
        "    for name_file in os.listdir(srcPath):\n",
        "        temp = []\n",
        "        for img_file in os.listdir(srcPath+name_file):      \n",
        "            temp.append(img_file)\n",
        "        if len(temp) == 0:\n",
        "            continue\n",
        "        randomfile = random.choice(temp)\n",
        "        path = os.path.join(srcPath+name_file+'/'+randomfile)\n",
        "        with open(path, 'rb') as rstream:\n",
        "                container = rstream.read()\n",
        "                path1 = os.path.join(dstPath+name_file)\n",
        "                if not os.path.exists(path1):\n",
        "                  os.mkdir(path1)\n",
        "                  path1 = os.path.join(dstPath+name_file+'/'+randomfile)\n",
        "  \n",
        "                with open(path1, 'wb') as wstream:\n",
        "                    wstream.write(container)\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "srcPath='/content/LFW/Align/'\n",
        "dstPath = '/content/new4/'\n",
        " \n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l26M164oB-l"
      },
      "source": [
        "random_copyfile(srcPath,dstPath)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG6bF23s2ScK"
      },
      "source": [
        "!zip -r /content/file2.zip /content/new4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlzIqb31z-L"
      },
      "source": [
        "!zip -r /content/file.zip /content/new3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1yJ6cET1_L0",
        "outputId": "6e51cc4a-f021-45f5-ecd6-f481e10de234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bc96586e-0928-4d41-9a54-01271331fb34\", \"file.zip\", 251429361)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-MyUXE2dWr",
        "outputId": "397cd835-5034-4acd-aa2a-c4f709108c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file2.zip\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a7077301-eb05-4872-976e-7b3a6208a697\", \"file2.zip\", 251500021)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpiDnco2aVR",
        "outputId": "8bc05b9a-8fce-417d-f563-bf63a5dda128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/rockey1006/classifier.git\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'classifier'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bUTQ4OH2vyo"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/file.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in different directory\n",
        "   zipObj.extractall('train')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypa82RBV3Fcx",
        "outputId": "dc466d4f-c17e-4ab9-873f-784e24fa8894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbhae-Aa3Kpu"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/vgg_face_weights.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in different directory\n",
        "   zipObj.extractall('vgg_face_weights/')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX5nZ8wV3OXH",
        "outputId": "98463352-b816-4e2a-b48a-e9741b911306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/classifier/Face2020.py\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-04 10:50:17.801777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-04 10:50:25.201905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-04 10:50:25.205230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.205895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-04 10:50:25.205956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-04 10:50:25.206022: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-04 10:50:25.306937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-04 10:50:25.307039: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-04 10:50:25.307102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-04 10:50:25.371197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-04 10:50:25.371293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-04 10:50:25.371420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.372117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.372664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-04 10:50:25.459882: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-11-04 10:50:25.460133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4af29180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-04 10:50:25.460164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-04 10:50:25.467856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.468559: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4af29500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-04 10:50:25.468585: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-11-04 10:50:25.468792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.469371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-04 10:50:25.469417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-04 10:50:25.469437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-04 10:50:25.469477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-04 10:50:25.469495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-04 10:50:25.469512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-04 10:50:25.469544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-04 10:50:25.469562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-04 10:50:25.469657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.470274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:25.470768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-04 10:50:25.473340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-04 10:50:29.303116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-04 10:50:29.303171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-11-04 10:50:29.303184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-11-04 10:50:29.309252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:29.310227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-04 10:50:29.311111: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-11-04 10:50:29.311182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13603 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "model loaded-------------\n",
            "2020-11-04 10:50:30.427314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-04 10:50:30.649757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "(5749, 2622)\n",
            "(5749,)\n",
            "Epoch 1/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 9.8404 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 9.1530 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 8.7132 - accuracy: 0.0014\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 8.4098 - accuracy: 0.0042\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 8.1377 - accuracy: 0.0115\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 7.8203 - accuracy: 0.0252\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 7.5094 - accuracy: 0.0553\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 7.1699 - accuracy: 0.1021\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 6.7730 - accuracy: 0.1788\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 6.3729 - accuracy: 0.2667\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 5.9299 - accuracy: 0.3738\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 5.4879 - accuracy: 0.4827\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 4.9827 - accuracy: 0.5982\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 4.5033 - accuracy: 0.7026\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 3.9900 - accuracy: 0.7916\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 3.4653 - accuracy: 0.8568\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 2.9879 - accuracy: 0.9102\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 2.5031 - accuracy: 0.9383\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 2.0812 - accuracy: 0.9623\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 1.6906 - accuracy: 0.9753\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 1.3714 - accuracy: 0.9868\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 1.0956 - accuracy: 0.9901\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.8705 - accuracy: 0.9936\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.7137 - accuracy: 0.9965\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.5661 - accuracy: 0.9983\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.4661 - accuracy: 0.9981\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3873 - accuracy: 0.9981\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.9984\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2708 - accuracy: 0.9988\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2387 - accuracy: 0.9993\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9988\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9993\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9991\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9990\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9997\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9995\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9990\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9990\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0756 - accuracy: 0.9991\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9991\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9993\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9990\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9991\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9991\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9995\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9993\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9991\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9991\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9990\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9988\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9988\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9991\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9990\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9991\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9988\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9993\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9993\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9990\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9990\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9990\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9990\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9991\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9990\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9990\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9991\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9990\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9981\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9983\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9988\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9991\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9993\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9993\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9993\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9991\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9993\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9991\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9943\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9990\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9990\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9991\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9993\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9995\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9995\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9995\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9993\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9993\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9991\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9993\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9993\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9993\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9990\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9993\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9976\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9957\n",
            "Evaluate on test data\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.8795\n",
            "test loss, test acc: [0.747674286365509, 0.8794572949409485]\n",
            "wrong data\n",
            "WARNING:tensorflow:From /content/classifier/FaceModel.py:79: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "2020-11-04 10:54:36.483166: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 137976000 exceeds 10% of free system memory.\n",
            "positions: (array([  30,   44,   78,   86,  101,  114,  115,  118,  129,  133,  137,\n",
            "        140,  144,  152,  162,  175,  176,  200,  201,  208,  210,  231,\n",
            "        241,  258,  264,  265,  279,  287,  289,  290,  304,  336,  358,\n",
            "        390,  407,  409,  415,  416,  419,  433,  435,  437,  451,  454,\n",
            "        463,  465,  482,  531,  551,  572,  579,  582,  593,  602,  609,\n",
            "        629,  631,  637,  643,  649,  650,  654,  657,  672,  677,  691,\n",
            "        692,  704,  719,  730,  739,  765,  777,  778,  783,  784,  808,\n",
            "        831,  832,  847,  854,  879,  893,  895,  896,  912,  913,  931,\n",
            "        936,  939,  951,  964,  967,  975,  976, 1017, 1019, 1022, 1023,\n",
            "       1037, 1062, 1079, 1081, 1083, 1084, 1094, 1097, 1102, 1105, 1109,\n",
            "       1130, 1142, 1149, 1158, 1159, 1166, 1168, 1180, 1187, 1191, 1194,\n",
            "       1208, 1212, 1220, 1229, 1230, 1231, 1246, 1259, 1260, 1263, 1264,\n",
            "       1272, 1273, 1278, 1286, 1288, 1289, 1296, 1298, 1300, 1303, 1305,\n",
            "       1306, 1319, 1321, 1326, 1336, 1351, 1361, 1372, 1375, 1396, 1401,\n",
            "       1404, 1405, 1406, 1407, 1414, 1418, 1426, 1434, 1435, 1446, 1447,\n",
            "       1459, 1468, 1491, 1496, 1503, 1506, 1511, 1526, 1546, 1588, 1609,\n",
            "       1624, 1627, 1629, 1640, 1643, 1646, 1653, 1659, 1668, 1669, 1672,\n",
            "       1676, 1683, 1684, 1705, 1707, 1716, 1719, 1723, 1724, 1735, 1754,\n",
            "       1759, 1782, 1784, 1802, 1812, 1813, 1816, 1817, 1822, 1837, 1842,\n",
            "       1848, 1851, 1876, 1886, 1890, 1895, 1898, 1900, 1903, 1908, 1924,\n",
            "       1937, 1951, 1952, 1953, 1956, 1968, 1972, 1984, 2002, 2010, 2013,\n",
            "       2020, 2055, 2062, 2066, 2068, 2069, 2075, 2080, 2105, 2123, 2136,\n",
            "       2139, 2143, 2145, 2167, 2169, 2174, 2183, 2185, 2186, 2190, 2198,\n",
            "       2214, 2234, 2239, 2242, 2244, 2253, 2257, 2259, 2262, 2266, 2280,\n",
            "       2286, 2288, 2291, 2299, 2302, 2303, 2310, 2315, 2316, 2317, 2324,\n",
            "       2337, 2356, 2364, 2377, 2381, 2413, 2420, 2432, 2433, 2434, 2442,\n",
            "       2448, 2449, 2477, 2485, 2496, 2506, 2519, 2520, 2532, 2535, 2538,\n",
            "       2552, 2557, 2562, 2563, 2566, 2570, 2571, 2579, 2589, 2597, 2619,\n",
            "       2632, 2633, 2652, 2661, 2663, 2673, 2676, 2679, 2709, 2722, 2724,\n",
            "       2727, 2728, 2732, 2735, 2737, 2738, 2763, 2764, 2766, 2771, 2775,\n",
            "       2790, 2793, 2795, 2803, 2823, 2825, 2846, 2857, 2862, 2865, 2879,\n",
            "       2892, 2893, 2895, 2902, 2928, 2940, 2945, 2964, 2975, 2987, 2990,\n",
            "       3006, 3015, 3030, 3041, 3049, 3051, 3054, 3065, 3083, 3092, 3096,\n",
            "       3098, 3124, 3131, 3132, 3136, 3152, 3153, 3160, 3168, 3187, 3191,\n",
            "       3192, 3214, 3216, 3231, 3237, 3250, 3261, 3267, 3283, 3284, 3290,\n",
            "       3312, 3320, 3335, 3338, 3339, 3341, 3347, 3357, 3363, 3376, 3385,\n",
            "       3395, 3396, 3414, 3418, 3430, 3431, 3442, 3446, 3452, 3462, 3475,\n",
            "       3481, 3495, 3498, 3500, 3509, 3511, 3515, 3516, 3536, 3537, 3546,\n",
            "       3549, 3552, 3567, 3569, 3572, 3576, 3585, 3589, 3591, 3599, 3603,\n",
            "       3606, 3614, 3620, 3626, 3632, 3635, 3637, 3641, 3667, 3704, 3706,\n",
            "       3707, 3731, 3744, 3757, 3772, 3775, 3776, 3780, 3782, 3789, 3796,\n",
            "       3798, 3801, 3802, 3812, 3815, 3817, 3826, 3836, 3846, 3848, 3853,\n",
            "       3862, 3881, 3909, 3933, 3941, 3949, 3952, 3981, 3992, 4005, 4013,\n",
            "       4015, 4017, 4023, 4025, 4039, 4041, 4048, 4064, 4086, 4094, 4103,\n",
            "       4110, 4126, 4127, 4135, 4137, 4144, 4147, 4151, 4154, 4156, 4162,\n",
            "       4166, 4176, 4179, 4192, 4198, 4202, 4209, 4211, 4213, 4223, 4235,\n",
            "       4247, 4250, 4252, 4260, 4262, 4265, 4292, 4304, 4306, 4307, 4324,\n",
            "       4336, 4355, 4368, 4373, 4376, 4388, 4394, 4396, 4412, 4443, 4455,\n",
            "       4466, 4480, 4515, 4521, 4527, 4533, 4534, 4536, 4549, 4553, 4561,\n",
            "       4562, 4564, 4565, 4580, 4594, 4598, 4604, 4607, 4632, 4635, 4656,\n",
            "       4673, 4692, 4693, 4707, 4709, 4729, 4731, 4737, 4738, 4741, 4745,\n",
            "       4769, 4784, 4785, 4789, 4800, 4802, 4805, 4808, 4811, 4814, 4817,\n",
            "       4824, 4834, 4835, 4836, 4838, 4844, 4845, 4861, 4864, 4873, 4876,\n",
            "       4903, 4904, 4916, 4924, 4930, 4932, 4944, 4950, 4957, 4958, 4968,\n",
            "       4973, 4976, 4985, 4988, 4998, 5000, 5011, 5015, 5021, 5038, 5039,\n",
            "       5042, 5043, 5052, 5074, 5077, 5081, 5096, 5101, 5110, 5123, 5125,\n",
            "       5127, 5130, 5132, 5139, 5140, 5142, 5146, 5173, 5174, 5178, 5184,\n",
            "       5190, 5193, 5206, 5216, 5217, 5230, 5236, 5256, 5257, 5267, 5271,\n",
            "       5272, 5280, 5287, 5299, 5310, 5319, 5320, 5328, 5336, 5344, 5347,\n",
            "       5362, 5383, 5386, 5398, 5399, 5406, 5407, 5410, 5427, 5434, 5443,\n",
            "       5447, 5459, 5465, 5468, 5474, 5489, 5494, 5515, 5537, 5540, 5558,\n",
            "       5565, 5577, 5584, 5594, 5609, 5615, 5618, 5620, 5621, 5634, 5637,\n",
            "       5650, 5659, 5676, 5684, 5686, 5703, 5704, 5728, 5734, 5741, 5747]),)\n",
            "done..\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}