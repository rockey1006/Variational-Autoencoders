{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from hyperspherical_vae.distributions import VonMisesFisher\n",
    "from hyperspherical_vae.distributions import HypersphericalUniform\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math,random,re\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "from keras.layers import Input, Dense, Lambda, Dropout,Activation, TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from os import environ\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# user defined function to change keras backend\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "       environ['KERAS_BACKEND'] = backend\n",
    "       reload(K)\n",
    "       assert K.backend() == backend\n",
    "\n",
    "# call the function with \"theano\"\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invariants\n",
    "ORDER_KEY=\"XILVAGMFYWEDQNHCRKSTPBZ-\"[::-1]\n",
    "ORDER_LIST=list(ORDER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "from helper_tools import *\n",
    "from helper_tools_for_plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points:  50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PABP_YEAST/115-210</td>\n",
       "      <td>qrdpslrkKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/203-294</td>\n",
       "      <td>..epangsPKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/534-625</td>\n",
       "      <td>..epangsPKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/312-398</td>\n",
       "      <td>........IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/33-112</td>\n",
       "      <td>........---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0                                PABP_YEAST/115-210   \n",
       "1  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/203-294   \n",
       "2  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/534-625   \n",
       "3  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/312-398   \n",
       "4   ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/33-112   \n",
       "\n",
       "                                            sequence  \n",
       "0  qrdpslrkKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATD...  \n",
       "1  ..epangsPKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKD...  \n",
       "2  ..epangsPKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKD...  \n",
       "3  ........IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVD...  \n",
       "4  ........---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRD...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pdataframe_from_alignment_file(\"PABP_YEAST_hmmerbit_plmc_n5_m30_f50_t0.2_r115-210_id100_b48.a2m\",50000)\n",
    "print (\"number of data points: \",len(data))\n",
    "data_set_size=len(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sequence: 96\n",
      "sample sequence:  qrdpslrkKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVAPHLSRkerdsq\n"
     ]
    }
   ],
   "source": [
    "print (\"length of sequence:\", len(data.iloc[0][\"sequence\"]))#, len(data.iloc[0][\"seq\"]))\n",
    "print (\"sample sequence: \", data.iloc[0][\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PABP_YEAST/115-210</td>\n",
       "      <td>qrdpslrkKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATD...</td>\n",
       "      <td>KGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/203-294</td>\n",
       "      <td>..epangsPKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKD...</td>\n",
       "      <td>PKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKDENGNSRGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/534-625</td>\n",
       "      <td>..epangsPKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKD...</td>\n",
       "      <td>PKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKDENGNSRGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/312-398</td>\n",
       "      <td>........IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVD...</td>\n",
       "      <td>IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVDSQGQSKGS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/33-112</td>\n",
       "      <td>........---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRD...</td>\n",
       "      <td>---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRDIRRVSLGY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0                                PABP_YEAST/115-210   \n",
       "1  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/203-294   \n",
       "2  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/534-625   \n",
       "3  ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/312-398   \n",
       "4   ur|UPI0004E53ABB|UniRef100_UPI0004E53ABB/33-112   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  qrdpslrkKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATD...   \n",
       "1  ..epangsPKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKD...   \n",
       "2  ..epangsPKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKD...   \n",
       "3  ........IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVD...   \n",
       "4  ........---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRD...   \n",
       "\n",
       "                                                 seq  \n",
       "0  KGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGF...  \n",
       "1  PKFFNVYVKNLPEKYTDDDLKSEFEAFGEITSAVVVKDENGNSRGF...  \n",
       "2  PKFFNVYVKNLPEKYTDDDLKSEFEASGEITSAVVVKDENGNSRGF...  \n",
       "3  IRGLNLYLKNLDDTIDDERLKELFRPFGTIISCKVMVDSQGQSKGS...  \n",
       "4  ---ASLYVGDLDLSVTEGQLFDLFSQIGPVASVRVCRDIRRVSLGY...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=index_of_non_lower_case_dot(data.iloc[0][\"sequence\"])\n",
    "data[\"seq\"]=list(map(prune_seq,data[\"sequence\"]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned sequence length: 82\n"
     ]
    }
   ],
   "source": [
    "print (\"pruned sequence length:\", len(data.iloc[0][\"seq\"]))\n",
    "PRUNED_SEQ_LENGTH=len(data.iloc[0][\"seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, array([0.03125   , 0.2       , 0.2       , 0.2       , 0.16666667,\n",
       "        0.2       , 0.16666667, 0.16666667, 0.0625    , 1.        ]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (\"PABP_YEAST_hmmerbit_t0.2_r50000.reweight\",\"rb\") as to_read:\n",
    "    new_weights=np.load(to_read)\n",
    "\n",
    "#new_weights=reweight_sequences(data[\"seq\"],0.1)\n",
    "len(new_weights),new_weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "(50000, 1968)\n"
     ]
    }
   ],
   "source": [
    "#Encode training data in one_hot vectors\n",
    "training_data_one_hot=[]\n",
    "labels=[]\n",
    "for i, row in data.iterrows():\n",
    "    training_data_one_hot.append(translate_string_to_one_hot(row[\"seq\"],ORDER_LIST))\n",
    "print (len(training_data_one_hot))\n",
    "#plt.imshow(training_data_one_hot[0],cmap=\"Greys\")\n",
    "training_data=np.array([np.array(list(sample.flatten())).T for sample in training_data_one_hot])\n",
    "print(training_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mutants:  1188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mutant                               K131V\n",
       "effect_prediction_epistatic         -10.06\n",
       "effect_prediction_independent     -3.36052\n",
       "linear                           0.0425856\n",
       "Name: 87, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_full=pd.read_csv(\n",
    "    \"PABP_YEAST_Fields2013-singles.csv\", sep=\";\", comment=\"#\"\n",
    ")\n",
    "print (\"number of mutants: \",len(exp_data_full))\n",
    "exp_data_full.head()\n",
    "exp_data_full.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <th>linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745161</td>\n",
       "      <td>0.592781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <td>0.745161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.592781</td>\n",
       "      <td>0.423680</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               effect_prediction_epistatic  \\\n",
       "effect_prediction_epistatic                       1.000000   \n",
       "effect_prediction_independent                     0.745161   \n",
       "linear                                            0.592781   \n",
       "\n",
       "                               effect_prediction_independent    linear  \n",
       "effect_prediction_epistatic                         0.745161  0.592781  \n",
       "effect_prediction_independent                       1.000000  0.423680  \n",
       "linear                                              0.423680  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_full.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mutant</th>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <th>linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>G126C</td>\n",
       "      <td>-5.663638</td>\n",
       "      <td>-0.027602</td>\n",
       "      <td>0.449027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>G126E</td>\n",
       "      <td>-6.611062</td>\n",
       "      <td>-1.827612</td>\n",
       "      <td>0.588928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>G126D</td>\n",
       "      <td>-7.270577</td>\n",
       "      <td>-1.180094</td>\n",
       "      <td>0.229853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>G126N</td>\n",
       "      <td>-5.809167</td>\n",
       "      <td>0.387443</td>\n",
       "      <td>0.679435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>G126S</td>\n",
       "      <td>-4.617248</td>\n",
       "      <td>0.661686</td>\n",
       "      <td>0.721788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>G126R</td>\n",
       "      <td>-5.582381</td>\n",
       "      <td>1.144148</td>\n",
       "      <td>0.313690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>G126W</td>\n",
       "      <td>-8.079901</td>\n",
       "      <td>-2.052391</td>\n",
       "      <td>0.226032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>G126V</td>\n",
       "      <td>-5.435631</td>\n",
       "      <td>-0.800307</td>\n",
       "      <td>0.230315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>N127A</td>\n",
       "      <td>-4.987206</td>\n",
       "      <td>-2.251823</td>\n",
       "      <td>0.062650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>N127C</td>\n",
       "      <td>-8.044181</td>\n",
       "      <td>-2.215639</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index mutant  effect_prediction_epistatic  effect_prediction_independent  \\\n",
       "0      1  G126C                    -5.663638                      -0.027602   \n",
       "1      2  G126E                    -6.611062                      -1.827612   \n",
       "2      3  G126D                    -7.270577                      -1.180094   \n",
       "3      4  G126N                    -5.809167                       0.387443   \n",
       "4      5  G126S                    -4.617248                       0.661686   \n",
       "5      6  G126R                    -5.582381                       1.144148   \n",
       "6      7  G126W                    -8.079901                      -2.052391   \n",
       "7      8  G126V                    -5.435631                      -0.800307   \n",
       "8      9  N127A                    -4.987206                      -2.251823   \n",
       "9     10  N127C                    -8.044181                      -2.215639   \n",
       "\n",
       "     linear  \n",
       "0  0.449027  \n",
       "1  0.588928  \n",
       "2  0.229853  \n",
       "3  0.679435  \n",
       "4  0.721788  \n",
       "5  0.313690  \n",
       "6  0.226032  \n",
       "7  0.230315  \n",
       "8  0.062650  \n",
       "9  0.024996  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFSET=117\n",
    "#Deciding offset requires investigating the dataset and alignment.\n",
    "exp_data_singles=pd.DataFrame(columns=exp_data_full.columns)\n",
    "#decide starting index depending on how the file is \"headered\"\n",
    "for i,row in exp_data_full[1:].iterrows():\n",
    "        pos=re.split(r'(\\d+)', row.mutant) \n",
    "        if int(pos[1])-OFFSET in indices:\n",
    "            exp_data_singles=exp_data_singles.append(row)\n",
    "exp_data_singles=exp_data_singles.reset_index()\n",
    "target_values_singles=list(exp_data_singles[\"linear\"])\n",
    "exp_data_singles.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187 1187\n",
      "[('K', 'K'), ('G', 'G'), ('S', 'S'), ('G', 'N'), ('N', 'N'), ('I', 'I'), ('F', 'F'), ('I', 'I'), ('K', 'K'), ('N', 'N')]\n"
     ]
    }
   ],
   "source": [
    "mutation_data=[re.split(r'(\\d+)', s) for s in exp_data_singles.mutant]\n",
    "wt_sequence=data.iloc[0].seq\n",
    "mutants=mutate_single(wt_sequence,mutation_data,offset=0,index=3) #note that you change index to 1\n",
    "\n",
    "#sanity checks\n",
    "print (len(mutants),len(exp_data_singles))\n",
    "#the mutant should be in the correct place\n",
    "print (list(zip(wt_sequence,mutants[3]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data with wt at 0 index\n",
    "one_hot_mutants=[]\n",
    "mutants_plus=[data.iloc[0][\"seq\"]]+mutants\n",
    "for mutant in mutants_plus:\n",
    "    one_hot_mutants.append(translate_string_to_one_hot(\"\".join(mutant),ORDER_LIST))\n",
    "\n",
    "test_data_plus=np.array([np.array(list(sample.flatten())).T for sample in one_hot_mutants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mutants:  36522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mutant                           G169W,F170V\n",
       "effect_prediction_epistatic          -18.161\n",
       "effect_prediction_independent       -15.1525\n",
       "XY_Enrichment_score                  0.05916\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_full=pd.read_csv(\n",
    "    \"PABP_YEAST_Fields2013-doubles.csv\", sep=\";\", comment=\"#\"\n",
    ")\n",
    "print (\"number of mutants: \",len(exp_data_full))\n",
    "exp_data_full.head()\n",
    "exp_data_full.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <th>XY_Enrichment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715371</td>\n",
       "      <td>0.620022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <td>0.715371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XY_Enrichment_score</th>\n",
       "      <td>0.620022</td>\n",
       "      <td>0.497743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               effect_prediction_epistatic  \\\n",
       "effect_prediction_epistatic                       1.000000   \n",
       "effect_prediction_independent                     0.715371   \n",
       "XY_Enrichment_score                               0.620022   \n",
       "\n",
       "                               effect_prediction_independent  \\\n",
       "effect_prediction_epistatic                         0.715371   \n",
       "effect_prediction_independent                       1.000000   \n",
       "XY_Enrichment_score                                 0.497743   \n",
       "\n",
       "                               XY_Enrichment_score  \n",
       "effect_prediction_epistatic               0.620022  \n",
       "effect_prediction_independent             0.497743  \n",
       "XY_Enrichment_score                       1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_full.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mutant</th>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <th>XY_Enrichment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>G169W,F170V</td>\n",
       "      <td>-18.161003</td>\n",
       "      <td>-15.152495</td>\n",
       "      <td>0.059160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>G169V,F170V</td>\n",
       "      <td>-13.753099</td>\n",
       "      <td>-8.845704</td>\n",
       "      <td>0.045765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>G169A,F170I</td>\n",
       "      <td>-9.115749</td>\n",
       "      <td>-3.954389</td>\n",
       "      <td>0.075799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>G169C,F170Y</td>\n",
       "      <td>-9.761077</td>\n",
       "      <td>-4.004533</td>\n",
       "      <td>0.700485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>G169A,F170S</td>\n",
       "      <td>-10.212144</td>\n",
       "      <td>-5.743002</td>\n",
       "      <td>0.061518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       mutant  effect_prediction_epistatic  \\\n",
       "0      0  G169W,F170V                   -18.161003   \n",
       "1      1  G169V,F170V                   -13.753099   \n",
       "2      2  G169A,F170I                    -9.115749   \n",
       "3      3  G169C,F170Y                    -9.761077   \n",
       "4      4  G169A,F170S                   -10.212144   \n",
       "\n",
       "   effect_prediction_independent  XY_Enrichment_score  \n",
       "0                     -15.152495             0.059160  \n",
       "1                      -8.845704             0.045765  \n",
       "2                      -3.954389             0.075799  \n",
       "3                      -4.004533             0.700485  \n",
       "4                      -5.743002             0.061518  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFSET=160\n",
    "#Deciding offset requires investigating the dataset and alignment.\n",
    "exp_data_doubles=pd.DataFrame(columns=exp_data_full.columns)\n",
    "#decide starting index depending on how the file is \"headered\"\n",
    "for i,row in exp_data_full[0:].iterrows():\n",
    "        pos=re.split(r'(\\d+)', row.mutant) \n",
    "        if int(pos[1])-OFFSET in indices and int(pos[3])-OFFSET in indices:\n",
    "            exp_data_doubles=exp_data_doubles.append(row)\n",
    "exp_data_doubles=exp_data_doubles.reset_index()\n",
    "exp_data_doubles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <th>XY_Enrichment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143941</td>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.117997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_prediction_epistatic</th>\n",
       "      <td>0.143941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773236</td>\n",
       "      <td>0.520277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_prediction_independent</th>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.773236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XY_Enrichment_score</th>\n",
       "      <td>0.117997</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.488397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  index  effect_prediction_epistatic  \\\n",
       "index                          1.000000                     0.143941   \n",
       "effect_prediction_epistatic    0.143941                     1.000000   \n",
       "effect_prediction_independent  0.140272                     0.773236   \n",
       "XY_Enrichment_score            0.117997                     0.520277   \n",
       "\n",
       "                               effect_prediction_independent  \\\n",
       "index                                               0.140272   \n",
       "effect_prediction_epistatic                         0.773236   \n",
       "effect_prediction_independent                       1.000000   \n",
       "XY_Enrichment_score                                 0.488397   \n",
       "\n",
       "                               XY_Enrichment_score  \n",
       "index                                     0.117997  \n",
       "effect_prediction_epistatic               0.520277  \n",
       "effect_prediction_independent             0.488397  \n",
       "XY_Enrichment_score                       1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_values_doubles=list(exp_data_doubles[\"XY_Enrichment_score\"])\n",
    "exp_data_doubles.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13876 13876\n",
      "[('G', 'G'), ('K', 'K'), ('S', 'S'), ('K', 'K'), ('G', 'G'), ('F', 'F'), ('G', 'A'), ('F', 'I'), ('V', 'V'), ('H', 'H')]\n"
     ]
    }
   ],
   "source": [
    "mutation_data1=[re.split(r'(\\d+)', s.split(\",\")[0]) for s in exp_data_doubles.mutant]\n",
    "mutation_data2=[re.split(r'(\\d+)', s.split(\",\")[1]) for s in exp_data_doubles.mutant]\n",
    "wt_sequence=data.iloc[0].seq\n",
    "\n",
    "mutants_double=mutate_double(wt_sequence,mutation_data1,mutation_data2,offset=0,index=46)\n",
    "\n",
    "#sanity checks\n",
    "print (len(mutants_double),len(exp_data_doubles))\n",
    "#the mutant should be in the correct place\n",
    "print (list(zip(wt_sequence,mutants_double[2]))[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data with wt at 0 index\n",
    "one_hot_mutants=[]\n",
    "mutants_plus=[data.iloc[0][\"seq\"]]+mutants_double\n",
    "for mutant in mutants_plus:\n",
    "    one_hot_mutants.append(translate_string_to_one_hot(\"\".join(mutant),ORDER_LIST))\n",
    "\n",
    "test_data_doubles_plus=np.array([np.array(list(sample.flatten())).T for sample in one_hot_mutants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data=np.vstack([test_data_plus,test_data_doubles_plus[1:]])\n",
    "all_test_data_flattened=np.array([np.array(list(sample.flatten())).T for sample in all_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rho_vs_mutants(keras.callbacks.Callback):\n",
    "    def __init__(self,mutants,test_set_size,aa_size,sequence_size):\n",
    "        self.mutants=mutants\n",
    "        self.sample_size=test_set_size\n",
    "        self.aa_size=aa_size\n",
    "        self.sequence_size=sequence_size\n",
    "        self.scores=[]\n",
    "        self.count_batch=0\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "    #This allows us to track the \"progress\" of the model on different epochs\n",
    "    def on_epoch_end(self,batch,logs):\n",
    "        x_decoded=vae.predict(test_data_plus[0:self.sample_size],batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(self.aa_size,self.sequence_size)\n",
    "        digit_wt = normalize(digit,axis=0, norm='l1')\n",
    "        wt_prob=compute_log_probability(digit,digit_wt)\n",
    "        fitnesses=[]\n",
    "        for sample in range(1,self.sample_size):\n",
    "            digit = x_decoded[sample].reshape(self.aa_size,self.sequence_size)\n",
    "            digit = normalize(digit,axis=0, norm='l1')\n",
    "            fitness=compute_log_probability(test_data_plus[sample].reshape(self.aa_size,self.sequence_size),digit)-wt_prob\n",
    "            fitnesses.append(fitness)\n",
    "        print (\",\"+str(spearmanr(fitnesses,target_values_singles[:self.sample_size-1])))\n",
    "        self.scores.append(spearmanr(fitnesses,target_values_singles[:self.sample_size-1])[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelVAE(object):\n",
    "\n",
    "    def __init__(self, x, h_dim, z_dim, activation=tf.nn.relu, distribution='normal'):\n",
    "        \"\"\"\n",
    "        ModelVAE initializer\n",
    "\n",
    "        :param x: placeholder for input\n",
    "        :param h_dim: dimension of the hidden layers\n",
    "        :param z_dim: dimension of the latent representation\n",
    "        :param activation: callable activation function\n",
    "        :param distribution: string either `normal` or `vmf`, indicates which distribution to use\n",
    "        \"\"\"\n",
    "        self.x, self.h_dim, self.z_dim, self.activation, self.distribution = x, h_dim, z_dim, activation, distribution\n",
    "\n",
    "        self.z_mean, self.z_var = self._encoder(self.x)\n",
    "\n",
    "        if distribution == 'normal':\n",
    "            self.q_z = tf.distributions.Normal(self.z_mean, self.z_var)\n",
    "        elif distribution == 'vmf':\n",
    "            self.q_z = VonMisesFisher(self.z_mean, self.z_var)\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        self.z = self.q_z.sample()\n",
    "\n",
    "        self.logits = self._decoder(self.z)\n",
    "\n",
    "    def _encoder(self, x):\n",
    "        \"\"\"\n",
    "        Encoder network\n",
    "\n",
    "        :param x: placeholder for input\n",
    "        :return: tuple `(z_mean, z_var)` with mean and concentration around the mean\n",
    "        \"\"\"\n",
    "        # dynamic binarization\n",
    "        x = tf.cast(tf.greater(x, tf.random_uniform(shape=tf.shape(x), dtype=x.dtype)), dtype=x.dtype)\n",
    "        \n",
    "        # 2 hidden layers encoder\n",
    "        h0 = tf.layers.dense(x, units=self.h_dim * 2, activation=self.activation)\n",
    "        h1 = tf.layers.dense(h0, units=self.h_dim, activation=self.activation)\n",
    "\n",
    "        if self.distribution == 'normal':\n",
    "            # compute mean and std of the normal distribution\n",
    "            z_mean = tf.layers.dense(h1, units=self.z_dim, activation=None)\n",
    "            z_var = tf.layers.dense(h1, units=self.z_dim, activation=tf.nn.softplus)\n",
    "        elif self.distribution == 'vmf':\n",
    "            # compute mean and concentration of the von Mises-Fisher\n",
    "            z_mean = tf.layers.dense(h1, units=self.z_dim, activation=lambda x: tf.nn.l2_normalize(x, axis=-1))\n",
    "            # the `+ 1` prevent collapsing behaviors\n",
    "            z_var = tf.layers.dense(h1, units=1, activation=tf.nn.softplus) + 1\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        return z_mean, z_var\n",
    "\n",
    "    def _decoder(self, z):\n",
    "        \"\"\"\n",
    "        Decoder network\n",
    "\n",
    "        :param z: tensor, latent representation of input (x)\n",
    "        :return: logits, `reconstruction = sigmoid(logits)`\n",
    "        \"\"\"\n",
    "        # 2 hidden layers decoder\n",
    "        h2 = tf.layers.dense(z, units=self.h_dim, activation=self.activation)\n",
    "        h2 = tf.layers.dense(h2, units=self.h_dim * 2, activation=self.activation)\n",
    "        logits = tf.layers.dense(h2, units=self.x.shape[-1], activation=None)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class OptimizerVAE(object):\n",
    "\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        OptimizerVAE initializer\n",
    "\n",
    "        :param model: a model object\n",
    "        :param learning_rate: float, learning rate of the optimizer\n",
    "        \"\"\"\n",
    "\n",
    "        # binary cross entropy error\n",
    "        self.bce = tf.nn.sigmoid_cross_entropy_with_logits(labels=model.x, logits=model.logits)\n",
    "        self.reconstruction_loss = tf.reduce_mean(tf.reduce_sum(self.bce, axis=-1))\n",
    "\n",
    "        if model.distribution == 'normal':\n",
    "            # KL divergence between normal approximate posterior and standard normal prior\n",
    "            self.p_z = tf.distributions.Normal(tf.zeros_like(model.z), tf.ones_like(model.z))\n",
    "            kl = model.q_z.kl_divergence(self.p_z)\n",
    "            self.kl = tf.reduce_mean(tf.reduce_sum(kl, axis=-1))\n",
    "        elif model.distribution == 'vmf':\n",
    "            # KL divergence between vMF approximate posterior and uniform hyper-spherical prior\n",
    "            self.p_z = HypersphericalUniform(model.z_dim - 1, dtype=model.x.dtype)\n",
    "            kl = model.q_z.kl_divergence(self.p_z)\n",
    "            self.kl = tf.reduce_mean(kl)\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        self.ELBO = - self.reconstruction_loss - self.kl\n",
    "\n",
    "        self.train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-self.ELBO)\n",
    "\n",
    "        self.print = {'recon loss': self.reconstruction_loss, 'ELBO': self.ELBO, 'KL': self.kl}\n",
    "\n",
    "\n",
    "def log_likelihood(model, optimizer, n=10):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model: model object\n",
    "    :param optimizer: optimizer object\n",
    "    :param n: number of MC samples\n",
    "    :return: MC estimate of log-likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    z = model.q_z.sample(n)\n",
    "\n",
    "    log_p_z = optimizer.p_z.log_prob(z)\n",
    "\n",
    "    if model.distribution == 'normal':\n",
    "        log_p_z = tf.reduce_sum(log_p_z, axis=-1)\n",
    "\n",
    "    log_p_x_z = -tf.reduce_sum(optimizer.bce, axis=-1)\n",
    "\n",
    "    log_q_z_x = model.q_z.log_prob(z)\n",
    "\n",
    "    if model.distribution == 'normal':\n",
    "        log_q_z_x = tf.reduce_sum(log_q_z_x, axis=-1)\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_logsumexp(\n",
    "        tf.transpose(log_p_x_z + log_p_z - log_q_z_x) - np.log(n), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Normal VAE #####\n",
      "0 {'KL': 0.12592505, 'ELBO': -1365.071, 'recon loss': 1364.9451}\n",
      "100 {'KL': 0.11927996, 'ELBO': -1364.9526, 'recon loss': 1364.8334}\n",
      "200 {'KL': 0.1630525, 'ELBO': -1365.2765, 'recon loss': 1365.1134}\n",
      "300 {'KL': 0.14344679, 'ELBO': -1364.9447, 'recon loss': 1364.8013}\n",
      "400 {'KL': 0.15069847, 'ELBO': -1364.9459, 'recon loss': 1364.7952}\n",
      "500 {'KL': 0.1354092, 'ELBO': -1364.8993, 'recon loss': 1364.7639}\n",
      "600 {'KL': 0.12574944, 'ELBO': -1364.894, 'recon loss': 1364.7683}\n",
      "700 {'KL': 0.16001925, 'ELBO': -1364.9957, 'recon loss': 1364.8357}\n",
      "800 {'KL': 0.12122164, 'ELBO': -1364.8813, 'recon loss': 1364.7601}\n",
      "900 {'KL': 0.12666322, 'ELBO': -1365.1824, 'recon loss': 1365.0557}\n",
      "0 {'KL': 0.12592505, 'ELBO': -1364.9617, 'recon loss': 1364.8357}\n",
      "100 {'KL': 0.11927996, 'ELBO': -1364.794, 'recon loss': 1364.6747}\n",
      "200 {'KL': 0.1630525, 'ELBO': -1365.0576, 'recon loss': 1364.8945}\n",
      "300 {'KL': 0.14344679, 'ELBO': -1365.0338, 'recon loss': 1364.8904}\n",
      "400 {'KL': 0.15069847, 'ELBO': -1364.9697, 'recon loss': 1364.819}\n",
      "500 {'KL': 0.1354092, 'ELBO': -1365.0895, 'recon loss': 1364.9541}\n",
      "600 {'KL': 0.12574944, 'ELBO': -1364.957, 'recon loss': 1364.8313}\n",
      "700 {'KL': 0.16001925, 'ELBO': -1364.9874, 'recon loss': 1364.8274}\n",
      "800 {'KL': 0.12122164, 'ELBO': -1365.1075, 'recon loss': 1364.9863}\n",
      "900 {'KL': 0.12666322, 'ELBO': -1365.0941, 'recon loss': 1364.9674}\n",
      "##### Hyper-spherical VAE #####\n",
      "0 {'KL': 4.9085245, 'ELBO': -217.50488, 'recon loss': 212.59636}\n",
      "100 {'KL': 4.7897034, 'ELBO': -14.170418, 'recon loss': 9.380714}\n",
      "200 {'KL': 4.936582, 'ELBO': -109.865036, 'recon loss': 104.92845}\n",
      "300 {'KL': 5.0370674, 'ELBO': -114.81555, 'recon loss': 109.77848}\n",
      "400 {'KL': 5.0487885, 'ELBO': -110.25946, 'recon loss': 105.21067}\n",
      "500 {'KL': 5.3300695, 'ELBO': -174.15808, 'recon loss': 168.82802}\n",
      "600 {'KL': 5.3515444, 'ELBO': -154.34932, 'recon loss': 148.99777}\n",
      "700 {'KL': 5.2117424, 'ELBO': -150.50047, 'recon loss': 145.28873}\n",
      "800 {'KL': 4.791732, 'ELBO': -28.64627, 'recon loss': 23.85454}\n",
      "900 {'KL': 4.7553177, 'ELBO': -47.969902, 'recon loss': 43.214584}\n",
      "0 {'KL': 5.247386, 'ELBO': -207.39734, 'recon loss': 202.14995}\n",
      "100 {'KL': 4.9833612, 'ELBO': -12.970278, 'recon loss': 7.986917}\n",
      "200 {'KL': 5.2361746, 'ELBO': -100.16297, 'recon loss': 94.926796}\n",
      "300 {'KL': 5.2971277, 'ELBO': -106.59013, 'recon loss': 101.29301}\n",
      "400 {'KL': 5.303009, 'ELBO': -102.618675, 'recon loss': 97.31567}\n",
      "500 {'KL': 5.5315895, 'ELBO': -166.6972, 'recon loss': 161.16562}\n",
      "600 {'KL': 5.542627, 'ELBO': -147.74881, 'recon loss': 142.20618}\n",
      "700 {'KL': 5.459564, 'ELBO': -127.35599, 'recon loss': 121.89642}\n",
      "800 {'KL': 4.9146895, 'ELBO': -23.549513, 'recon loss': 18.634823}\n",
      "900 {'KL': 4.9657793, 'ELBO': -45.414642, 'recon loss': 40.448864}\n"
     ]
    }
   ],
   "source": [
    "# hidden dimension and dimension of latent space\n",
    "H_DIM = 128\n",
    "Z_DIM = 2\n",
    "batch_size = 20\n",
    "original_dim=len(ORDER_LIST)*PRUNED_SEQ_LENGTH\n",
    "output_dim=len(ORDER_LIST)*PRUNED_SEQ_LENGTH\n",
    "latent_dim = 2\n",
    "intermediate_dim = 250\n",
    "nb_epoch = 2\n",
    "epsilon_std = 1.0\n",
    "np.random.seed(42) \n",
    "dataset_size = 50000\n",
    "# digit placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, 1968))\n",
    "\n",
    "# normal VAE\n",
    "modelN = ModelVAE(x=x, h_dim=H_DIM, z_dim=Z_DIM, distribution='normal')\n",
    "optimizerN = OptimizerVAE(modelN)\n",
    "\n",
    "# hyper-spherical VAE\n",
    "modelS = ModelVAE(x=x, h_dim=H_DIM, z_dim=Z_DIM + 1, distribution='vmf')\n",
    "optimizerS = OptimizerVAE(modelS)\n",
    "x_train=training_data[:data_set_size] #this needs to be divisible by batch size and less than or equal to dataset size\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "print('##### Normal VAE #####')\n",
    "for epich in range(nb_epoch):\n",
    "    for i in range(1000):\n",
    "    # training\n",
    "        start = (i*batch_size) % dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        session.run(optimizerS.train_step, {modelN.x:x_train[start:end]})\n",
    "\n",
    "    # every 100 iteration plot validation\n",
    "        if i % 100 == 0:\n",
    "            print(i, session.run({**optimizerN.print}, {modelN.x: x_train[start:end]}))\n",
    "\n",
    "\n",
    "print('##### Hyper-spherical VAE #####')\n",
    "for epich in range(nb_epoch):\n",
    "\n",
    "    for i in range(1000):\n",
    "    # training\n",
    "        start = (i*batch_size) % dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        session.run(optimizerS.train_step, {modelS.x:x_train[start:end]})\n",
    "\n",
    "\n",
    "    # every 100 iteration plot validation\n",
    "        if i % 100 == 0:\n",
    "            print(i, session.run({**optimizerS.print}, {modelS.x: x_train[start:end]}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
