{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import scipy.io as scio\n",
    "import gzip\n",
    "from six.moves import cPickle\n",
    "import sys\n",
    "import  theano\n",
    "import  theano.tensor as T\n",
    "import math\n",
    "from keras.models import model_from_json\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "    \n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "#=====================================\n",
    "def cluster_acc(Y_pred, Y):\n",
    "  from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "  assert Y_pred.size == Y.size\n",
    "  D = max(Y_pred.max(), Y.max())+1\n",
    "  w = np.zeros((D,D), dtype=np.int64)\n",
    "  for i in range(Y_pred.size):\n",
    "    w[Y_pred[i], Y[i]] += 1\n",
    "  ind = linear_assignment(w.max() - w)\n",
    "  return sum([w[i,j] for i,j in ind])*1.0/Y_pred.size,ind\n",
    "             \n",
    "#==================================================\n",
    "def load_data():\n",
    "    path = 'c:/Users/wruoq/VaDE-master/dataset/mnist/mnist.pkl.gz'\n",
    "    if path.endswith(\".gz\"):\n",
    "        f = gzip.open(path, 'rb')\n",
    "    else:\n",
    "        f = open(path, 'rb')\n",
    "\n",
    "    if sys.version_info < (3,):\n",
    "        (x_train, y_train), (x_test, y_test) = cPickle.load(f)\n",
    "    else:\n",
    "        (x_train, y_train), (x_test, y_test) = cPickle.load(f, encoding=\"bytes\")\n",
    "\n",
    "    f.close()\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "    x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "    X = np.concatenate((x_train,x_test))\n",
    "    Y = np.concatenate((y_train,y_test))\n",
    "    return X,Y\n",
    "\n",
    "        \n",
    "def gmm_para_init():\n",
    "    \n",
    "    gmm_weights=scio.loadmat('c:/Users/wruoq/VaDE-master/trained_model_weights/mnist_weights_gmm.mat')\n",
    "    u_init=gmm_weights['u']\n",
    "    lambda_init=gmm_weights['lambda']\n",
    "    theta_init=np.squeeze(gmm_weights['theta'])\n",
    "    \n",
    "    theta_p=theano.shared(np.asarray(theta_init,dtype=theano.config.floatX),name=\"pi\")\n",
    "    u_p=theano.shared(np.asarray(u_init,dtype=theano.config.floatX),name=\"u\")\n",
    "    lambda_p=theano.shared(np.asarray(lambda_init,dtype=theano.config.floatX),name=\"lambda\")\n",
    "    return theta_p,u_p,lambda_p\n",
    "\n",
    "#==========================\n",
    "def generation_init():\n",
    "    gene_weights=scio.loadmat('c:/Users/wruoq/VaDE-master/trained_model_weights/mnist_gene.mat')\n",
    "    u_gene=gene_weights['u']\n",
    "    lambda_gene=gene_weights['lambda']\n",
    "    theta_gene=np.squeeze(gene_weights['theta'])\n",
    "    gene = model_from_json(open('c:/Users/wruoq/VaDE-master/trained_model_weights/mnist_gene.json').read())\n",
    "    gene.load_weights('c:/Users/wruoq/VaDE-master/trained_model_weights/mnist_gene_nn.h5')\n",
    "    return gene,theta_gene,u_gene,lambda_gene\n",
    "#================================\n",
    "def get_gamma(tempz):\n",
    "    temp_Z=T.transpose(K.repeat(tempz,n_centroid),[0,2,1])\n",
    "    temp_u_tensor3=T.repeat(u_p.dimshuffle('x',0,1),batch_size,axis=0)\n",
    "    temp_lambda_tensor3=T.repeat(lambda_p.dimshuffle('x',0,1),batch_size,axis=0)\n",
    "    temp_theta_tensor3=theta_p.dimshuffle('x','x',0)*T.ones((batch_size,latent_dim,n_centroid))\n",
    "    \n",
    "    temp_p_c_z=K.exp(K.sum((K.log(temp_theta_tensor3)-0.5*K.log(2*math.pi*temp_lambda_tensor3)-\\\n",
    "                       K.square(temp_Z-temp_u_tensor3)/(2*temp_lambda_tensor3)),axis=1))\n",
    "    return temp_p_c_z/K.sum(temp_p_c_z,axis=-1,keepdims=True)\n",
    "#=====================================================\n",
    "\n",
    "ispretrain = True\n",
    "batch_size = 100\n",
    "latent_dim = 10\n",
    "intermediate_dim = [500,500,2000]\n",
    "theano.config.floatX='float32'\n",
    "X,Y = load_data()\n",
    "original_dim = 784\n",
    "n_centroid = 10 \n",
    "theta_p, u_p, lambda_p = gmm_para_init()\n",
    "#===================\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim[0], activation='relu')(x)\n",
    "h = Dense(intermediate_dim[1], activation='relu')(h)\n",
    "h = Dense(intermediate_dim[2], activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "h_decoded = Dense(intermediate_dim[-1], activation='relu')(z)\n",
    "h_decoded = Dense(intermediate_dim[-2], activation='relu')(h_decoded)\n",
    "h_decoded = Dense(intermediate_dim[-3], activation='relu')(h_decoded)\n",
    "x_decoded_mean = Dense(original_dim, activation='sigmoid')(h_decoded)\n",
    "\n",
    "#========================\n",
    "p_c_z = Lambda(get_gamma, output_shape=(n_centroid,))(z_mean)\n",
    "sample_output = Model(x, z_mean)\n",
    "p_c_z_output = Model(x, p_c_z)\n",
    "#===========================================      \n",
    "vade = Model(x, x_decoded_mean)\n",
    "vade.load_weights('c:/Users/wruoq/VaDE-master/trained_model_weights/mnist_weights_nn.h5')\n",
    "\n",
    "accuracy,ind = cluster_acc(np.argmax(p_c_z_output.predict(X,batch_size=batch_size),axis=1),Y)\n",
    "print ('MNIST dataset VaDE - clustering accuracy: %.2f%%'%(accuracy*100))\n",
    "\n",
    "#==================   digits generation\n",
    "\n",
    "gene,g_theta,g_u,g_lambda = generation_init()\n",
    "\n",
    "def mnist_gene():\n",
    "    index=np.asarray(ind)[:,1]\n",
    "    mnist_nice_png=np.zeros((280,280))\n",
    "    for i in range(10):\n",
    "        k=np.where(index==i)[0][0]\n",
    "        u=g_u[:,k]\n",
    "        l=g_lambda[:,k]\n",
    "        sample_n=10\n",
    "        count=0\n",
    "        while count<sample_n:\n",
    "            z_sample=np.random.multivariate_normal(u,np.diag(l),(1,))\n",
    "            p=get_posterior(z_sample,g_u,g_lambda,g_theta)[k]\n",
    "            if p>0.999:\n",
    "                img=gene.predict(z_sample).reshape((28,28))*255.0\n",
    "                mnist_nice_png[i*28:(i+1)*28,count*28:(count+1)*28]=img\n",
    "                count+=1\n",
    "    return np.asarray(mnist_nice_png,dtype=np.uint8)     \n",
    "\n",
    "def get_posterior(z,u,l,sita):\n",
    "    z_m=np.repeat(np.transpose(z),n_centroid,1)\n",
    "    posterior=np.exp(np.sum((np.log(sita)-0.5*np.log(2*math.pi*l)-\\\n",
    "                       np.square(z_m-u)/(2*l)),axis=0))\n",
    "    return posterior/np.sum(posterior,axis=-1,keepdims=True)\n",
    "\n",
    "digit_image = mnist_gene()\n",
    "plt.imshow(digit_image,cmap=cm.gray)\n",
    "plt.show()\n",
    "#Image.fromarray(digit_image).save('digits.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
